{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Reviews on The Lion King (2019) from Rotten Tomatoes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description:\n",
    "Our goal is to perform sentiment analysis on user reviews about the movie 'The Lion King(2019)'. After the analysis the production company expects us to give some take aways that could help them with the future projects.\n",
    "\n",
    "### Problem Approach:\n",
    "1. We have to extract 3000 reviews from rotten tomatoes.\n",
    "2. After initial pre processing we have to perform Exploratory data analysis on the reviews using word clouds, ngrams etc.\n",
    "3. This is a binary classification problem. We need to use supervised classification methods and classify the reviews into positive and negative reviews.\n",
    "4. Perform cluster analysis on the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section we are extracting the reviews from rotten tomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating headers for our request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Referer':'https://www.rottentomatoes.com/m/the_lion_king_2019/reviews?type=user','User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36','X-Requested-With':'XMLHttpRequest',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Referer': 'https://www.rottentomatoes.com/m/the_lion_king_2019/reviews?type=user',\n",
       " 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36',\n",
       " 'X-Requested-With': 'XMLHttpRequest'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.rottentomatoes.com/napi/movie/9057c2cf-7cab-317f-876f-e50b245ca76e/reviews/user' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below code is a rough draft to create the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload1 = {'direction': 'next','endCursor': '','startCursor': ''}\n",
    "# r = s.get(url, headers=headers, params=payload1)    # GET Call \n",
    "# data1 = r.json()\n",
    "\n",
    "# data1\n",
    "\n",
    "# payload2 = {'direction': 'next','endCursor': 'eyJyZWFsbV91c2VySWQiOiJGYW5kYW5nb19DMjExNTA4RS1CNjAwLTQ0RTAtQTI4OS1DNDNFRURGMzA4MzEiLCJlbXNJZCI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZSIsImVtc0lkX2hhc1Jldmlld0lzVmlzaWJsZSI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZV9UIiwiY3JlYXRlRGF0ZSI6IjIwMTktMDgtMThUMDM6Mjg6NTAuNzAwWiJ9',\n",
    "#   'startCursor': None}\n",
    "\n",
    "# r = s.get(url, headers=headers, params=payload2)    # GET Call \n",
    "# data2 = r.json()\n",
    "\n",
    "# data2\n",
    "\n",
    "# payload3 = {'direction': 'next','endCursor': 'eyJyZWFsbV91c2VySWQiOiJSVF8yNjAzMTQyNTYiLCJlbXNJZCI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZSIsImVtc0lkX2hhc1Jldmlld0lzVmlzaWJsZSI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZV9UIiwiY3JlYXRlRGF0ZSI6IjIwMTktMDgtMThUMDE6NDM6MTYuMjk2WiJ9',\n",
    "#   'startCursor': 'eyJyZWFsbV91c2VySWQiOiJGYW5kYW5nb185YzIyMDUwMi0wNDZiLTRiOTgtYTBkMS1hZDI3MWVkNjExZjgiLCJlbXNJZCI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZSIsImVtc0lkX2hhc1Jldmlld0lzVmlzaWJsZSI6IjkwNTdjMmNmLTdjYWItMzE3Zi04NzZmLWU1MGIyNDVjYTc2ZV9UIiwiY3JlYXRlRGF0ZSI6IjIwMTktMDgtMThUMDM6MjU6NDUuNTgzWiJ9'}\n",
    "\n",
    "# r = s.get(url, headers=headers, params=payload3)    # GET Call \n",
    "# data3 = r.json()\n",
    "\n",
    "# data3\n",
    "\n",
    "# data1['reviews'].append(data2['reviews'])\n",
    "\n",
    "# data1['reviews'].append(data3['reviews'])\n",
    "\n",
    "# data1['reviews']\n",
    "\n",
    "# data1['pageInfo']['startCursor']\n",
    "\n",
    "# data1['pageInfo']['endCursor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract 3000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'direction': 'next','endCursor': '','startCursor':''}\n",
    "r = s.get(url, headers=headers, params=payload)    # GET Call \n",
    "data = r.json() # Extracting the reviews from the first page.\n",
    "allreviews = [] # Empty list to store all the reviews\n",
    "allreviews.append(data['reviews']) # Appending the first 10 reviews to the allreviews list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,299): # We need to extract 3000 reviews. we have 10 per each page.\n",
    "    temp_start = data['pageInfo']['startCursor'] # temp_start stores the startCursor from previous pageInfo\n",
    "    temp_end = data['pageInfo']['endCursor'] # temp_end stores the endCursor from previous pageInfo\n",
    "    payload = {'direction': 'next','endCursor': temp_end,'startCursor': temp_start} # Creating payload with latest parameters\n",
    "    r = s.get(url, headers=headers, params=payload)   \n",
    "    data = r.json()\n",
    "    allreviews.append(data['reviews']) # Appending the 10 reviews per iteration to the allreviews list.\n",
    "    print(i) # To check iterations\n",
    "    time.sleep(5) # Time delay to save the ip from getting blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allreviews) # We have 300 * 10 Reviews in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkp_allreviews = allreviews.copy() # Keeping a backup of allreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreviews_flat = [item for sublist in allreviews for item in sublist] # Making a flat list of 3000 elements from nested list of 300 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allreviews_flat) # We have 3000 Reviews in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkp_allreviews_flat = allreviews_flat.copy() # Keeping a backup of allreviews_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Account link in users dict is having NONE values. So unable to use json_normalize to create a data frame. As a work around I have extracted users dict as a list and saved it into users_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = [item.pop('user') for item in allreviews_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allreviews_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the dataframes from users_list and allreviews_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allreviews_df = json_normalize(allreviews_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = json_normalize(users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountLink</th>\n",
       "      <th>displayName</th>\n",
       "      <th>realm</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>James</td>\n",
       "      <td>Fandango</td>\n",
       "      <td>F11791BD-B3C7-4C1C-937D-A9D2FBAC55E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael M</td>\n",
       "      <td>Fandango</td>\n",
       "      <td>9F003606-9CC5-4335-AD39-25AF59B6CB11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wendy K</td>\n",
       "      <td>Fandango</td>\n",
       "      <td>d8ed9d30-ea8c-49c7-8a0b-251c4115b6af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Fandango</td>\n",
       "      <td>e6b35e3d-054f-4f3d-94d6-6f56a5e33ce3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yolanda</td>\n",
       "      <td>Fandango</td>\n",
       "      <td>e9085918-7ad2-4769-883a-40ce9510dc5b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accountLink displayName     realm                                userId\n",
       "0         NaN       James  Fandango  F11791BD-B3C7-4C1C-937D-A9D2FBAC55E2\n",
       "1         NaN   Michael M  Fandango  9F003606-9CC5-4335-AD39-25AF59B6CB11\n",
       "2         NaN     Wendy K  Fandango  d8ed9d30-ea8c-49c7-8a0b-251c4115b6af\n",
       "3         NaN        Tina  Fandango  e6b35e3d-054f-4f3d-94d6-6f56a5e33ce3\n",
       "4         NaN     Yolanda  Fandango  e9085918-7ad2-4769-883a-40ce9510dc5b"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createDate</th>\n",
       "      <th>displayImageUrl</th>\n",
       "      <th>displayName</th>\n",
       "      <th>hasProfanity</th>\n",
       "      <th>hasSpoilers</th>\n",
       "      <th>isSuperReviewer</th>\n",
       "      <th>isVerified</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>timeFromCreation</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-19T06:07:06.109Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>STAR_4</td>\n",
       "      <td>Really enjoyed it. The songs were amazing and ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31m ago</td>\n",
       "      <td>2019-08-19T06:07:06.109Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-19T05:34:01.006Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>STAR_5</td>\n",
       "      <td>Realky enjoyable. We've seen the original anim...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1h ago</td>\n",
       "      <td>2019-08-19T05:34:01.006Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-19T05:16:59.696Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wendy K</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>STAR_5</td>\n",
       "      <td>Beautiful! Loved it!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1h ago</td>\n",
       "      <td>2019-08-19T05:16:59.696Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-19T05:16:07.012Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tina</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>STAR_5</td>\n",
       "      <td>Absolutely loved the movie, it had my emotions...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1h ago</td>\n",
       "      <td>2019-08-19T05:16:07.012Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-19T04:54:52.352Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yolanda</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>STAR_5</td>\n",
       "      <td>Tha movie was phenomenal</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2h ago</td>\n",
       "      <td>2019-08-19T04:54:52.352Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 createDate displayImageUrl displayName  hasProfanity  \\\n",
       "0  2019-08-19T06:07:06.109Z             NaN       James         False   \n",
       "1  2019-08-19T05:34:01.006Z             NaN   Michael M         False   \n",
       "2  2019-08-19T05:16:59.696Z             NaN     Wendy K         False   \n",
       "3  2019-08-19T05:16:07.012Z             NaN        Tina         False   \n",
       "4  2019-08-19T04:54:52.352Z             NaN     Yolanda         False   \n",
       "\n",
       "   hasSpoilers  isSuperReviewer  isVerified  rating  \\\n",
       "0        False            False       False  STAR_4   \n",
       "1        False            False        True  STAR_5   \n",
       "2        False            False        True  STAR_5   \n",
       "3        False            False        True  STAR_5   \n",
       "4        False            False        True  STAR_5   \n",
       "\n",
       "                                              review  score timeFromCreation  \\\n",
       "0  Really enjoyed it. The songs were amazing and ...    4.0          31m ago   \n",
       "1  Realky enjoyable. We've seen the original anim...    5.0           1h ago   \n",
       "2                               Beautiful! Loved it!    5.0           1h ago   \n",
       "3  Absolutely loved the movie, it had my emotions...    5.0           1h ago   \n",
       "4                           Tha movie was phenomenal    5.0           2h ago   \n",
       "\n",
       "                 updateDate  primary_key  \n",
       "0  2019-08-19T06:07:06.109Z            0  \n",
       "1  2019-08-19T05:34:01.006Z            1  \n",
       "2  2019-08-19T05:16:59.696Z            2  \n",
       "3  2019-08-19T05:16:07.012Z            3  \n",
       "4  2019-08-19T04:54:52.352Z            4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allreviews_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want work on users and reviews seperately and merge them on primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['primary_key'] = list(range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreviews_df['primary_key'] = list(range(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_csv('users_df_3000.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreviews_df.to_csv('alreviews_df_3000.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
